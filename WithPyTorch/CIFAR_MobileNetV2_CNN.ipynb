{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pt0rApOvI-C9"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#\n",
    "# FILE\n",
    "#\n",
    "#   CIFAR_MobileNetV2_CNN.ipynb\n",
    "#\n",
    "# DESCRIPTION\n",
    "#\n",
    "#   Creates a convolutional neural network model designed for the CIFAR-10 data\n",
    "#   set based on MobileNetV2 using PyTorch.\n",
    "#\n",
    "#   Two python classes are defined in this file:\n",
    "#      1. MobileNetV2Bottleneck: A building block for the model based on the\n",
    "#         MobileNetV2 bottleneck block.\n",
    "#      2. Model: Creates the convolutional neural network model using the\n",
    "#         building block class MobileNetV2Bottleneck.\n",
    "#\n",
    "#   There are five distinct layers in the model: the encoder tail, encoder\n",
    "#   level 0, encoder level 1, encoder level 2, and the decoder. The layer\n",
    "#   details and number of MACs per block are detailed below:\n",
    "#      T.  Conv 1x1 stride=2  | 21600     MACs\n",
    "#      ---------------------------------------\n",
    "#      0.1 Bottleneck S=1 t=1 | 3225600   MACs\n",
    "#      0.2 Bottleneck S=2 t=6 | 368148480 MACs\n",
    "#      0.3 Bottleneck S=2 t=6 | 92798976  MACs\n",
    "#      ---------------------------------------\n",
    "#      1.1 Bottleneck S=1 t=6 | 89653248  MACs\n",
    "#      1.2 Bottleneck S=1 t=6 | 92798976  MACs\n",
    "#      1.3 Bottleneck S=1 t=6 | 23199744  MACs\n",
    "#      ---------------------------------------\n",
    "#      2.1 Bottleneck S=2 t=6 | 22413312  MACs\n",
    "#      2.2 Bottleneck S=2 t=6 | 88080384  MACs\n",
    "#      2.3 Bottleneck S=2 t=6 | 88080384  MACs\n",
    "#      2.4 Bottleneck S=1 t=6 | 88080384  MACs\n",
    "#      ---------------------------------------\n",
    "#      D.1 Average Pool       | 512       MACs\n",
    "#      D.2 Conv 1x1 stride=1  | 262144    MACs\n",
    "#      D.3 Flatten            | 0         MACs\n",
    "#      D.4 Linear             | 5120      MACs\n",
    "#\n",
    "#   After being trained for 60 epochs with Adam as the optimizer and a learning\n",
    "#   rate schedule of linear warmup followed by cosine decay, the final accuracy\n",
    "#   achieved on CIFAR-10 is 86.10%. The results are shown below:\n",
    "#   (Note: training code is not provided in this file).\n",
    "#      Epoch  0 lr = 0.000010 avg loss = 0.063959 accuracy = 32.32\n",
    "#      Epoch  1 lr = 0.000208 avg loss = 0.049835 accuracy = 52.11\n",
    "#      Epoch  2 lr = 0.000406 avg loss = 0.042698 accuracy = 57.54\n",
    "#      Epoch  3 lr = 0.000604 avg loss = 0.038423 accuracy = 60.94\n",
    "#      Epoch  4 lr = 0.000802 avg loss = 0.035498 accuracy = 64.32\n",
    "#      Epoch  5 lr = 0.001000 avg loss = 0.033053 accuracy = 67.69\n",
    "#      Epoch  6 lr = 0.001000 avg loss = 0.030139 accuracy = 70.57\n",
    "#      Epoch  7 lr = 0.000998 avg loss = 0.027921 accuracy = 72.55\n",
    "#      Epoch  8 lr = 0.000996 avg loss = 0.026018 accuracy = 73.01\n",
    "#      Epoch  9 lr = 0.000993 avg loss = 0.024296 accuracy = 74.49\n",
    "#      Epoch 10 lr = 0.000990 avg loss = 0.023007 accuracy = 75.05\n",
    "#      Epoch 11 lr = 0.000985 avg loss = 0.021833 accuracy = 77.13\n",
    "#      Epoch 12 lr = 0.000980 avg loss = 0.020620 accuracy = 77.21\n",
    "#      Epoch 13 lr = 0.000973 avg loss = 0.019535 accuracy = 78.58\n",
    "#      Epoch 14 lr = 0.000966 avg loss = 0.018739 accuracy = 78.76\n",
    "#      Epoch 15 lr = 0.000958 avg loss = 0.017912 accuracy = 79.28\n",
    "#      Epoch 16 lr = 0.000950 avg loss = 0.017341 accuracy = 80.45\n",
    "#      Epoch 17 lr = 0.000940 avg loss = 0.016679 accuracy = 81.21\n",
    "#      Epoch 18 lr = 0.000930 avg loss = 0.015876 accuracy = 80.71\n",
    "#      Epoch 19 lr = 0.000919 avg loss = 0.015329 accuracy = 81.05\n",
    "#      Epoch 20 lr = 0.000907 avg loss = 0.014723 accuracy = 80.93\n",
    "#      Epoch 21 lr = 0.000895 avg loss = 0.014145 accuracy = 80.89\n",
    "#      Epoch 22 lr = 0.000881 avg loss = 0.013655 accuracy = 82.03\n",
    "#      Epoch 23 lr = 0.000867 avg loss = 0.013055 accuracy = 81.71\n",
    "#      Epoch 24 lr = 0.000853 avg loss = 0.012706 accuracy = 81.84\n",
    "#      Epoch 25 lr = 0.000837 avg loss = 0.012210 accuracy = 82.34\n",
    "#      Epoch 26 lr = 0.000821 avg loss = 0.011783 accuracy = 82.92\n",
    "#      Epoch 27 lr = 0.000804 avg loss = 0.011280 accuracy = 82.51\n",
    "#      Epoch 28 lr = 0.000787 avg loss = 0.010752 accuracy = 83.07\n",
    "#      Epoch 29 lr = 0.000768 avg loss = 0.010456 accuracy = 82.33\n",
    "#      Epoch 30 lr = 0.000750 avg loss = 0.009876 accuracy = 83.29\n",
    "#      Epoch 31 lr = 0.000730 avg loss = 0.009717 accuracy = 83.57\n",
    "#      Epoch 32 lr = 0.000710 avg loss = 0.009173 accuracy = 83.59\n",
    "#      Epoch 33 lr = 0.000689 avg loss = 0.008730 accuracy = 83.83\n",
    "#      Epoch 34 lr = 0.000668 avg loss = 0.008331 accuracy = 83.81\n",
    "#      Epoch 35 lr = 0.000646 avg loss = 0.008141 accuracy = 83.51\n",
    "#      Epoch 36 lr = 0.000624 avg loss = 0.007546 accuracy = 84.13\n",
    "#      Epoch 37 lr = 0.000601 avg loss = 0.007341 accuracy = 83.79\n",
    "#      Epoch 38 lr = 0.000578 avg loss = 0.006916 accuracy = 83.77\n",
    "#      Epoch 39 lr = 0.000554 avg loss = 0.006608 accuracy = 83.32\n",
    "#      Epoch 40 lr = 0.000530 avg loss = 0.006328 accuracy = 83.73\n",
    "#      Epoch 41 lr = 0.000505 avg loss = 0.005971 accuracy = 84.50\n",
    "#      Epoch 42 lr = 0.000480 avg loss = 0.005560 accuracy = 84.61\n",
    "#      Epoch 43 lr = 0.000454 avg loss = 0.005245 accuracy = 84.25\n",
    "#      Epoch 44 lr = 0.000428 avg loss = 0.004837 accuracy = 84.26\n",
    "#      Epoch 45 lr = 0.000402 avg loss = 0.004562 accuracy = 84.81\n",
    "#      Epoch 46 lr = 0.000376 avg loss = 0.004474 accuracy = 84.59\n",
    "#      Epoch 47 lr = 0.000349 avg loss = 0.004081 accuracy = 84.68\n",
    "#      Epoch 48 lr = 0.000321 avg loss = 0.003792 accuracy = 85.29\n",
    "#      Epoch 49 lr = 0.000294 avg loss = 0.003449 accuracy = 85.08\n",
    "#      Epoch 50 lr = 0.000266 avg loss = 0.003152 accuracy = 85.23\n",
    "#      Epoch 51 lr = 0.000238 avg loss = 0.002954 accuracy = 84.97\n",
    "#      Epoch 52 lr = 0.000210 avg loss = 0.002787 accuracy = 85.38\n",
    "#      Epoch 53 lr = 0.000182 avg loss = 0.002564 accuracy = 85.23\n",
    "#      Epoch 54 lr = 0.000153 avg loss = 0.002220 accuracy = 85.74\n",
    "#      Epoch 55 lr = 0.000125 avg loss = 0.002080 accuracy = 85.73\n",
    "#      Epoch 56 lr = 0.000096 avg loss = 0.001954 accuracy = 85.83\n",
    "#      Epoch 57 lr = 0.000068 avg loss = 0.001744 accuracy = 85.95\n",
    "#      Epoch 58 lr = 0.000039 avg loss = 0.001576 accuracy = 86.00\n",
    "#      Epoch 59 lr = 0.000010 avg loss = 0.001587 accuracy = 86.10\n",
    "#\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILam27XGJxME"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#\n",
    "# IMPORT\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn    as nn\n",
    "\n",
    "# version check\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ze5cIIr7JuGt"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#\n",
    "# PARAMETERS\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# data (general)\n",
    "DATA_NUM_CHANNELS = 3\n",
    "DATA_NUM_CLASSES  = 10\n",
    "\n",
    "# model\n",
    "MODEL_LEVEL_0_BLOCKS            = 3\n",
    "MODEL_LEVEL_1_BLOCKS            = 3\n",
    "MODEL_LEVEL_2_BLOCKS            = 4\n",
    "MODEL_TAIL_END_CHANNELS         = 32\n",
    "MODEL_LEVEL_0_IDENTITY_CHANNELS = 128\n",
    "MODEL_LEVEL_1_IDENTITY_CHANNELS = 256\n",
    "MODEL_LEVEL_2_IDENTITY_CHANNELS = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUzLHspUexcs"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#\n",
    "# NETWORK BUILDING BLOCKS\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# mobile net v2 bottleneck\n",
    "class MobileNetV2Bottleneck(nn.Module):\n",
    "\n",
    "    # initialization\n",
    "    def __init__(self, C_in, C_out, S, t):\n",
    "\n",
    "        # parent initialization\n",
    "        super(MobileNetV2Bottleneck, self).__init__()\n",
    "\n",
    "        # identity\n",
    "        if ((C_in != C_out) or (S > 1)):\n",
    "            self.conv0_present = True\n",
    "            self.conv0         = nn.Conv2d(C_in, C_out, (1, 1), stride=(S, S), padding=(0, 0), dilation=(1, 1), groups=1, bias=False, padding_mode='zeros')\n",
    "        else:\n",
    "            self.conv0_present = False\n",
    "\n",
    "        # set C_res\n",
    "        C_res = C_in * t\n",
    "\n",
    "        # residual\n",
    "        self.bn1   = nn.BatchNorm2d(C_in, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.relu1 = nn.ReLU6()\n",
    "        self.conv1 = nn.Conv2d(C_in, C_res, (1, 1), stride=(1, 1), padding=(0, 0), dilation=(1, 1), groups=1, bias=False, padding_mode='zeros')\n",
    "        self.bn2   = nn.BatchNorm2d(C_res, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.relu2 = nn.ReLU6()\n",
    "        self.conv2 = nn.Conv2d(C_res, C_res, (3, 3), stride=(S, S), padding=(1, 1), dilation=(1, 1), groups=C_res, bias=False, padding_mode='zeros')\n",
    "        self.bn3   = nn.BatchNorm2d(C_res, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.relu3 = nn.ReLU6()\n",
    "        self.conv3 = nn.Conv2d(C_res, C_out, (1, 1), stride=(1, 1), padding=(0, 0), dilation=(1, 1), groups=1, bias=False, padding_mode='zeros')\n",
    "\n",
    "    # forward path\n",
    "    def forward(self, x):\n",
    "\n",
    "        # residual\n",
    "        res = self.bn1(x)\n",
    "        res = self.relu1(res)\n",
    "        res = self.conv1(res)\n",
    "        res = self.bn2(res)\n",
    "        res = self.relu2(res)\n",
    "        res = self.conv2(res)\n",
    "        res = self.bn3(res)\n",
    "        res = self.relu3(res)\n",
    "        res = self.conv3(res)\n",
    "\n",
    "        # identity\n",
    "        if (self.conv0_present == True):\n",
    "            x = self.conv0(x)\n",
    "\n",
    "        # summation\n",
    "        x = x + res\n",
    "\n",
    "        # return\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YKXajuMLJRue"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#\n",
    "# NETWORK\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# define\n",
    "class Model(nn.Module):\n",
    "\n",
    "    # initialization\n",
    "    def __init__(self, data_num_channels, data_num_classes, model_level_0_blocks, model_level_1_blocks, model_level_2_blocks, model_tail_end_channels, model_level_0_identity_channels, model_level_1_identity_channels, model_level_2_identity_channels):\n",
    "\n",
    "        # parent initialization\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # encoder tail\n",
    "        self.enc_tail = nn.ModuleList()\n",
    "        self.enc_tail.append(nn.Conv2d(data_num_channels, model_tail_end_channels, (1, 1), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=1, bias=False, padding_mode='zeros'))\n",
    "\n",
    "        # encoder level 0\n",
    "        self.enc_0 = nn.ModuleList()\n",
    "        self.enc_0.append(MobileNetV2Bottleneck(model_tail_end_channels, model_level_0_identity_channels, 1, 1))\n",
    "        for n in range(model_level_0_blocks - 1):\n",
    "            self.enc_0.append(MobileNetV2Bottleneck(model_level_0_identity_channels, model_level_0_identity_channels, 2, 6))\n",
    "\n",
    "        # encoder level 1\n",
    "        self.enc_1 = nn.ModuleList()\n",
    "        self.enc_1.append(MobileNetV2Bottleneck(model_level_0_identity_channels, model_level_1_identity_channels, 1, 6))\n",
    "        for n in range(model_level_1_blocks - 1):\n",
    "            self.enc_1.append(MobileNetV2Bottleneck(model_level_1_identity_channels, model_level_1_identity_channels, 1, 6))\n",
    "\n",
    "        # encoder level 2\n",
    "        self.enc_2 = nn.ModuleList()\n",
    "        self.enc_2.append(MobileNetV2Bottleneck(model_level_1_identity_channels, model_level_2_identity_channels, 2, 6))\n",
    "        for n in range(model_level_2_blocks - 2):\n",
    "            self.enc_2.append(MobileNetV2Bottleneck(model_level_2_identity_channels, model_level_2_identity_channels, 2, 6))\n",
    "        self.enc_2.append(MobileNetV2Bottleneck(model_level_2_identity_channels, model_level_2_identity_channels, 1, 6))\n",
    "\n",
    "        # encoder level 2 complete the bn - relu6 pattern\n",
    "        self.enc_2.append(nn.BatchNorm2d(model_level_2_identity_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
    "        self.enc_2.append(nn.ReLU6())\n",
    "\n",
    "        # decoder\n",
    "        self.dec = nn.ModuleList()\n",
    "        self.dec.append(nn.AdaptiveAvgPool2d((1, 1)))\n",
    "        self.dec.append(nn.Conv2d(model_level_2_identity_channels, model_level_2_identity_channels, (1, 1), stride=(1, 1), padding=(0, 0), dilation=(1, 1), groups=1, bias=True, padding_mode='zeros'))\n",
    "        self.dec.append(nn.Flatten())\n",
    "        self.dec.append(nn.Linear(model_level_2_identity_channels, data_num_classes, bias=True))\n",
    "\n",
    "    # forward path\n",
    "    def forward(self, x):\n",
    "\n",
    "        # encoder tail\n",
    "        for layer in self.enc_tail:\n",
    "            x = layer(x)\n",
    "\n",
    "        # encoder level 0\n",
    "        for layer in self.enc_0:\n",
    "            x = layer(x)\n",
    "\n",
    "        # encoder level 1\n",
    "        for layer in self.enc_1:\n",
    "            x = layer(x)\n",
    "\n",
    "        # encoder level 2\n",
    "        for layer in self.enc_2:\n",
    "            x = layer(x)\n",
    "\n",
    "        # decoder\n",
    "        for layer in self.dec:\n",
    "            x = layer(x)\n",
    "\n",
    "        # return\n",
    "        return x\n",
    "\n",
    "# create\n",
    "model = Model(DATA_NUM_CHANNELS, DATA_NUM_CLASSES, MODEL_LEVEL_0_BLOCKS, MODEL_LEVEL_1_BLOCKS, MODEL_LEVEL_2_BLOCKS, MODEL_TAIL_END_CHANNELS, MODEL_LEVEL_0_IDENTITY_CHANNELS, MODEL_LEVEL_1_IDENTITY_CHANNELS, MODEL_LEVEL_2_IDENTITY_CHANNELS)\n",
    "\n",
    "# visualization\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CIFAR_MobileNetV2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
